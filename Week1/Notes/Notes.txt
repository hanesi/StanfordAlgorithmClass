Karatsuba Multiplication

Ex: Multiply 1234 * 5678
Sequence looks different than grade school multiplication

x = 1234
y = 5678

a = 56, b = 78, c = 12, d = 34
do a few operations between those 2 digit numbers and collect.

1) compute a * c
2) compute b * d
3) compute (a +b)(c +d)
4) compute Step 3 - 2 - 1
5) pad a * c with 4 0's, b * d with none, Step 4 with 0, add them up

x * y = 10^n(ac) + 10^(n/2)(ad + bc) + bc

only care about 3 quantities, so only want 3 recursive calls

1) compute ac
2) compute bd
3) recursively compute (a+b)(c+d) = ac+ad+bc+bd
Gauss' Trick: 3 - 1 - 2 = ad + bc
upshot: only need 3 recursive calls and some additions


Merge Sort

Good intro to divide and conquer
  improves over selection, insertion, and bubble sorts (O(n)^2)

Sorting problem:
Input: array of n numbers, unsorted
Output: array sorted in increasing order
>>>5,4,1,3,2,7,9
>>>1,2,3,4,5,7,9

Merge Sort - recursive, calls itself on smaller arrays than the input
Split array into 2, sort each, combine them (merge)

Pseudocode

recursive calls and merge

c = output array (length n)
a = first sorted array
b = second sorted array
i, j = counters to traverse a and b (set to 1)

Minimum element must be first
for k = 1 to n
  if a(i) < b(j)
    c(k) = a(i)
    i++
  elif b(j) < a(i)
    c(k) = b(j)
    j++

Running Time?
Key question - running merge sort on n numbers?
  runtime ~ num lines of code executed

2 operations to set i,j = 1
for loop runs n times, 4 operations each time
  +1 to k,j, or i plus setting the output array

4m + 2 can call it at least 6m because m>=1

Claim - never need more that 6nLog(n) + 6n operations

Runtime analysis - substantiate above claim

recursion tree proof
    root 0  #outer call
        / \
       0   0 #level 1
      / \ / \
     0  0 0  0 #level 2

There are Log(n) levels; decreases by a factor of 2 each level
Allows us to add up code level by level

at level j, how many sub problems? 2^j (merge sort doubles each time)
for each one, what's the input size? n/j^2

Guiding Principles of Algorithms

Worst-case analysis: use upper bound (6n) for all cases
  (as opposed to average case or benchmarks; req's domain knowledge)
  Usually easier to analyze
Won't worry about lower order terms or constant factors
  justifications - easier, constants depend on architecture, lose very little
Asymptotic analysis: focus on running for LARGE input steps
  justifications - only big problems are interesting
    dont need algorithms for small datasets

What is fast?
  worst case scenario runtime grows slowly with input size
    (want linear runtime)


Asymptotic Analysis - The Gist

Importance - vocab for design and analysis of algo's
Sweet spot for high level reasoning
  coarse enough to suppress language/compiler-dependent details
  sharp enough for useful comparisons betweens algorithms
    (better/worse sort approaches, for example)

High level idea - suppress leading constant factors and lower order terms
  lower order terms become irrelevant with large inputs
  constant factors are too dependent on architecture

  ex 6nlog(n) + 6n -> nLog(n) (Big Oh Notation)

Big Oh Notation
let T(n) = function on n = 1,2,3,4, usually worst case scenario


Divide and conquer
Input: array containing numbers 1 to n
Output: number of inversions, i.e. pairs (i,j) of array indicies with
  i < j and a[i] > a[j]

ex: [1,3,5,2,4,6]
inversions: [5,2], [3,2], [5,4]
motivation - numerical similarity measure between 2 ranked lists
  e.g. collaborative filtering

Brute force method - double for loop O(n^2) in time
  can we do better? Yes, divide and conquer

call inversion [i,j] with i < j
left if i,j <= n/2
right if i,j > n/2
split if i <= n/2 < j <- need separate process

Count(array A, length n)
  if n =1 retrun 0
  else
    x = count(1st half of A, n/2)
    y = count(2nd half of A, n/2)
    z = count SplitInv(A,n) <- not currently implemented
  return x + y + z

goal: implement linear CountSplitInv

Piggyback on merge sort
key idea - have recursive call count inversions and sort

merge subroutine naturally uncovers inversions

SortAndCount(array A, length n)
  if n =1 retrun 0
  else
    x = SortAndcount(1st half of A, n/2)
    y = SortAndcount(2nd half of A, n/2)
    z = MergeAndCountSplitInv(A,n) <- not currently implemented
  return x + y + z

if you have an array with no split inversions, the left list
  is smaller than everything on the right

Example:
consider merging [1,2,3] and [2,4,6]
output = [1,2,3,4,5,6]
when 2 copied to output, discover split inversions [3,2] amd [5,4]
copied 4, find inversion [5,2]

if x copied first, then x < y, no inversion.
if y copied, x > y, signifying a split inversion

while merging, keep running total of split inversions (where  x > y)


Matrix Multiplications

3 matrices, x * y = z
all n x n
where Zij = ith row of x * jth row of y
Input size = n^2

Ex: n = 2
a b   e f    ae+bg af+bh
    x     =
c d   g h    ce+dg cf+dh

have to identify multiplications of smaller matrices

idea: divide matrix into quadrants
recursively compute products (8 of them)
do the additions (O(n^2))
runtime is cubic though, follows master method

Strassen's algo
step 1 compute only 7 cleverly chosen products
step 2 do the necessary subtractions/additions
better than cubic time!


Closest Pair Problem

input: set P of n points in the plane
want SQRT of the square of the differences of the points

assume: have distinct coordinates
brute force takes On^2

1D version, all points are on one line, do a merge sort
return closest pair (smallest difference) O(n) time
goal O(nlogn) time for 2D version

1) make copies of points sorted by X and by Y (Px, Py) (nlogn time)
  (sorting is a free primitive)
2) use divide and conquer

Let Q = left half, R = right half
form Qx, Qy, Rx, Ry (takes On time)
p1,q1 = closest pair (Qx, Qy)
p2,q2 = closest pair (Rx, Ry)
p3,q3 = closest split pair (Px, Py)
return best of the above

Key idea - only need to bother computing closest split pair
  in unlucky case where distance is less than both p1,q1 and p2,q2

check delta between first and second recursive calls
only care about points that are within delta [x-d, y-d]

Sy = points of P with X coord in the delta region (+/- d)
best = delta, best_pair = null
for i = 1 to Sy - 7
  for j = 1 to 7
    let Piz = ith, (i +j)th points of Sy
    if d(p1,q1) < best
      best_pair = (p1,q1), dist = d(p1,q1)
